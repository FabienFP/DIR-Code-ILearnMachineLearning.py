{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Theory on CART - Classification And Regression Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Gini Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini index is measure of impurity. It is used as cost function in <b>CART</b> (Classification And Regression Trees) to evaluate splits in dataets. Gini index gives an idea of how good a split is by measuring how mixed the classes are in the two groups created by the split. For example for a two class problem, a perfect separation results in a Gini score of 0, whereas the worst case split that results in 50/50 classes in each group result in a Gini score of 0.5. If a dataset $T$ contains examples from $n$ classes, Gini Index $Gini(T)$ is defined as:\n",
    "\n",
    "$$Gini(T) = 1 - \\sum_{j=1}^{n}p_{j}^{2}$$\n",
    "\n",
    "If a dataset $T$ is split into two subsets $T_{1}$ and $T_{2}$ with sizes $N_{1}$ and $N_{2}$ respectively, the Gini index of split data contains examples from $n$ classes, te Gini indix $(T)$ is defined as:\n",
    "\n",
    "$$Gini_{split}(T) = \\frac{N_{1}}{N}gini(T_{1}) + \\frac{N_{2}}{N}gini(T_{2})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homogeneity of sample can be also calculated using entrophy. If the sample is completely homogeneous the entropy is zero and if the sample is an equally divided it has entropy of one. Entropy $E(T)$ is defined as:\n",
    "\n",
    "$$E(T) = \\sum_{j=1}^{n}-p_{j}log_{2}p_{j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a dataset $T$ is split into two subsets $T_{1}$ and $T_{2}$ with sizes $N_{1}$ and $N_{2}$ respectively, the Gini index of split data contains examples from $n$ classes, te Gini indix $(T)$ is defined as:\n",
    "\n",
    "$$E(T, X) = \\frac{N_{1}}{N}E(T_{1}) + \\frac{N_{2}}{N}E(T_{2})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
